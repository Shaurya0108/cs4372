{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaurya0108/cs4372/blob/main/Recommendation_System_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNf2dAQQNnZO"
      },
      "source": [
        "# Recommendation Systems\n",
        "We will use the surprise library of Python. Details are available at: http://surpriselib.com\n",
        "\n",
        "We will first work through an example using a built-in dataset and then use a custom one.\n",
        "\n",
        "First, ensure that you have the library installed and then load the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvbeyqcHNgjl",
        "outputId": "7498d21b-42ef-4fb8-e093-945010c6424b"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-vnJ02aOa9S"
      },
      "source": [
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import NormalPredictor\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import KNNBaseline\n",
        "from surprise import Dataset\n",
        "from surprise import get_dataset_dir\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39SWtmcqOpuq"
      },
      "source": [
        "For a recommendation system, we require a file containing at least 3 things - userId, itemId, and rating. Any other information is not needed, but can be good for human analysis of results.\n",
        "\n",
        "Let's load the built in ml-100k dataset that contains movies and ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZd8BnboOmse",
        "outputId": "b1821cb8-fd56-42dd-d183-b53c1ff8c49f"
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed),\n",
        "data = Dataset.load_builtin('ml-100k')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0kJP7rEPHYn",
        "outputId": "03d672ea-e433-4e54-cdea-5ad4e3aaf9ff"
      },
      "source": [
        "# Let's see what files come with the dataset\n",
        "!ls /root/.surprise_data/ml-100k/ml-100k/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62q26F3SPvft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810cb609-7bd8-4dca-ad22-42142ee85d06"
      },
      "source": [
        "# TODO: Show the first 10 lines of the u.data, and u.item files\n",
        "!head -10 /root/.surprise_data/ml-100k/ml-100k/u.data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196\t242\t3\t881250949\n",
            "186\t302\t3\t891717742\n",
            "22\t377\t1\t878887116\n",
            "244\t51\t2\t880606923\n",
            "166\t346\t1\t886397596\n",
            "298\t474\t4\t884182806\n",
            "115\t265\t2\t881171488\n",
            "253\t465\t5\t891628467\n",
            "305\t451\t3\t886324817\n",
            "6\t86\t3\t883603013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaB5-nihRtuS"
      },
      "source": [
        "## Algorithms\n",
        "Let's look at some of the algorithms available with the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBJ1MkWyRswn"
      },
      "source": [
        "?KNNBaseline"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp2R7SCxSbcy"
      },
      "source": [
        "The nearest neighbor methods works by searching for neighbors using the utility matrix. Let's create a nearest neighbor first by item and user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSiyKhGVP78C",
        "outputId": "5a890462-be99-476f-f9bd-4e741663b1c3"
      },
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "trainset = data.build_full_trainset()\n",
        "# we are going to use item-item similarity\n",
        "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "algo = KNNBaseline(sim_options=sim_options)\n",
        "algo.fit(trainset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7a5f40c5fbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilbee2N1TV4H",
        "outputId": "e695b186-0d00-4089-e5aa-dae46adff9e2"
      },
      "source": [
        "!head -10 /root/.surprise_data/ml-100k/ml-100k/u.item"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
            "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\n",
            "6|Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995||http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "7|Twelve Monkeys (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|1|0|0|0\n",
            "8|Babe (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Babe%20(1995)|0|0|0|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "9|Dead Man Walking (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "10|Richard III (1995)|22-Jan-1996||http://us.imdb.com/M/title-exact?Richard%20III%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|1|0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDqZoURXW-kX"
      },
      "source": [
        "# Id to Name Lookup\n",
        "Let's write a small method that will convert id to name, and name to id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOnbUClBTKlf"
      },
      "source": [
        "def read_item_names():\n",
        "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
        "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
        "    \"\"\"\n",
        "\n",
        "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
        "    rid_to_name = {}\n",
        "    name_to_rid = {}\n",
        "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            line = line.split('|')\n",
        "            rid_to_name[line[0]] = line[1]\n",
        "            name_to_rid[line[1]] = line[0]\n",
        "\n",
        "    return rid_to_name, name_to_rid"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8vv_EKmUiIi"
      },
      "source": [
        "# test this function\n",
        "rid_to_name, name_to_rid = read_item_names()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ApUrTtaKWvhR",
        "outputId": "cabe721e-14f0-4bce-af60-c873a92a61bb"
      },
      "source": [
        "rid_to_name[\"1\"]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Toy Story (1995)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Pl5szE0WynN",
        "outputId": "c95de37c-72a9-41e8-f67e-3cf50bd73be6"
      },
      "source": [
        "name_to_rid[\"Twelve Monkeys (1995)\"]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1KEIIY2Xjas",
        "outputId": "ce1c1e8d-7d58-4c97-ffe6-b199edf8f58e"
      },
      "source": [
        "# Find top 10 movies similar to movie with id 100\n",
        "\n",
        "movie_inner_id = algo.trainset.to_inner_iid(\"200\")\n",
        "movie_name = rid_to_name[\"200\"]\n",
        "\n",
        "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
        "movie_neighbors = algo.get_neighbors(movie_inner_id, k=10)\n",
        "\n",
        "# Convert inner ids of the neighbors into names.\n",
        "movie_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
        "                       for inner_id in movie_neighbors)\n",
        "movie_neighbors = (rid_to_name[rid]\n",
        "                       for rid in movie_neighbors)\n",
        "\n",
        "print()\n",
        "\n",
        "print('The 10 nearest neighbors of ' + movie_name)\n",
        "for movie in movie_neighbors:\n",
        "    print(movie)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The 10 nearest neighbors of Shining, The (1980)\n",
            "Bonnie and Clyde (1967)\n",
            "Godfather: Part II, The (1974)\n",
            "Alien (1979)\n",
            "Godfather, The (1972)\n",
            "Raging Bull (1980)\n",
            "Pulp Fiction (1994)\n",
            "One Flew Over the Cuckoo's Nest (1975)\n",
            "Carrie (1976)\n",
            "Koyaanisqatsi (1983)\n",
            "His Girl Friday (1940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kcnxpDaZTxL"
      },
      "source": [
        "Let's now apply the algorithm and figure out it's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USd7X5jZX7pX",
        "outputId": "bb76ca1a-3b20-435e-b22c-9272c6889ff0"
      },
      "source": [
        "testset = trainset.build_testset()\n",
        "predictions = algo.test(testset)\n",
        "# RMSE should be low as we are biased\n",
        "accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.4807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48071109787164656"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASSc6E5waLOl"
      },
      "source": [
        "Now, let's also try some baseline methods. Follow the code available here:\n",
        "\n",
        "https://github.com/NicolasHug/Surprise/blob/fa7455880192383f01475162b4cbd310d91d29ca/examples/baselines_conf.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYMS8igapJy"
      },
      "source": [
        "For more elaborate testing and validation, follow steps mentioned here\n",
        "https://github.com/NicolasHug/Surprise/blob/fa7455880192383f01475162b4cbd310d91d29ca/examples/grid_search_usage.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIywdaaWa4t8"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this part, you will use the dataset that is provided along with the following Kaggle competition\n",
        "\n",
        "https://www.kaggle.com/arashnic/book-recommendation-dataset\n",
        "\n",
        "\n",
        "I have uploaded the files for you at\n",
        "\n",
        "Ratings file - https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Ratings.csv\n",
        "\n",
        "Books file - https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Books.csv\n",
        "\n",
        "\n",
        "Follow the steps below to create a recommendation system from this data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, KNNBasic, KNNBaseline, SVD, BaselineOnly\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise.model_selection import cross_validate\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "DDAgbw8_dXxT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fFRYXmGrXOX"
      },
      "source": [
        "# TODO: Read both the data files into Pandas dataframes\n",
        "ratings_df = pd.read_csv('https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Ratings.csv')\n",
        "books_df = pd.read_csv('https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Books.csv')\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34iXAs_rw0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85ce0ac-d1d5-4d6b-b74a-b4c3f2e65119"
      },
      "source": [
        "# TODO: Answer the following questions:\n",
        "# How many ratings and how many books are there in the dataset\n",
        "print(f\"Number of ratings: {len(ratings_df)}\")\n",
        "print(f\"Number of unique books: {len(books_df)}\")\n",
        "\n",
        "# Find the top 10 books have received the highest count of ratings. You should output the id of the book, its title, and the count of ratings received.\n",
        "rating_counts = ratings_df['ISBN'].value_counts().reset_index()\n",
        "rating_counts.columns = ['ISBN', 'Rating_Count']\n",
        "top_10_books = pd.merge(\n",
        "    rating_counts,\n",
        "    books_df[['ISBN', 'Book-Title']],\n",
        "    on='ISBN'\n",
        ")[['ISBN', 'Book-Title', 'Rating_Count']].head(10)\n",
        "\n",
        "# Renaming the books\n",
        "top_10_books.columns = ['ISBN', 'Book Title', 'Rating Count']\n",
        "\n",
        "print(\"Top 10 Most Rated Books:\")\n",
        "print(top_10_books.to_string(index=False))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ratings: 1149780\n",
            "Number of unique books: 271360\n",
            "Top 10 Most Rated Books:\n",
            "      ISBN                                         Book Title  Rating Count\n",
            "0971880107                                        Wild Animus          2502\n",
            "0316666343                          The Lovely Bones: A Novel          1295\n",
            "0385504209                                  The Da Vinci Code           883\n",
            "0060928336    Divine Secrets of the Ya-Ya Sisterhood: A Novel           732\n",
            "0312195516                The Red Tent (Bestselling Backlist)           723\n",
            "044023722X                                    A Painted House           647\n",
            "0142001740                            The Secret Life of Bees           615\n",
            "067976402X                             Snow Falling on Cedars           614\n",
            "0671027360                                Angels &amp; Demons           586\n",
            "0446672211 Where the Heart Is (Oprah's Book Club (Paperback))           585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4IFExALsZM1"
      },
      "source": [
        "# TODO: Important - You may not be able use the whole dataset for model creation, so you need to create a\n",
        "# smaller sample to proceeed further\n",
        "# Here is what I did:\n",
        "# reviews_short = reviews.sample(n = 1000, random_state = 42)\n",
        "# you can try larger values of n, if the system allows you.\n",
        "valid_isbns = set(ratings_df['ISBN']).intersection(set(books_df['ISBN']))\n",
        "ratings_df = ratings_df[ratings_df['ISBN'].isin(valid_isbns)] #\n",
        "\n",
        "np.random.seed(42)\n",
        "sample_size = 1000\n",
        "ratings_sample = ratings_df.sample(n=sample_size, random_state=42)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4lAFc8iwBmB"
      },
      "source": [
        "# TODO: Use the data to create a custom dataset in the surprise library\n",
        "# Steps to do this are: https://surprise.readthedocs.io/en/stable/getting_started.html#use-a-custom-dataset\n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "data = Dataset.load_from_df(\n",
        "    ratings_sample[['User-ID', 'ISBN', 'Book-Rating']],\n",
        "    reader\n",
        ")\n",
        "trainset = data.build_full_trainset()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C1mn_LuwNtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab356046-2db9-4733-be57-4d994de03c57"
      },
      "source": [
        "# TODO: Choose a book at random and use the KNNBasic algorithm to find out its 10 closest neighbors. Do the results make\n",
        "# sense?\n",
        "knn = KNNBasic(sim_options={'user_based': False})\n",
        "knn.fit(trainset)\n",
        "\n",
        "random_isbn = ratings_sample[ratings_sample['ISBN'].isin(books_df['ISBN'])]['ISBN'].sample(1).iloc[0]\n",
        "book_inner_id = trainset.to_inner_iid(random_isbn)\n",
        "selected_book_title = books_df[books_df['ISBN'] == random_isbn]['Book-Title'].iloc[0]\n",
        "print(f\"\\nSelected Book: {selected_book_title}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "Selected Book: Work, Sex and Rugby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGB7wKwxO6q"
      },
      "source": [
        "# TODO: Use ParameterGridSearch on the following algorithms and compare their accuracies. You are free to decide\n",
        "# which specific parameters to use:\n",
        "# 1. KNNBaseline\n",
        "# 2. ALS - Baseline\n",
        "# 3. SGD - Baseline\n",
        "# 4. SVD\n",
        "# You should use a cv value of at least 3 and compare the mean accuracy of each of the algorithms\n",
        "# Comment on whether there is significant differences in the results of the algorithms\n",
        "\n",
        "# Defining parameter grids\n",
        "param_grid_knn = {\n",
        "    'k': [3, 5],\n",
        "    'min_k': [1],\n",
        "    'sim_options': {\n",
        "        'name': ['cosine'],\n",
        "        'user_based': [False]\n",
        "    }\n",
        "}\n",
        "\n",
        "param_grid_baseline_als = {\n",
        "    'bsl_options': {\n",
        "        'method': ['als'],\n",
        "        'n_epochs': [5],\n",
        "        'reg_u': [12],\n",
        "        'reg_i': [5]\n",
        "    }\n",
        "}\n",
        "\n",
        "param_grid_baseline_sgd = {\n",
        "    'bsl_options': {\n",
        "        'method': ['sgd'],\n",
        "        'learning_rate': [0.005],\n",
        "        'n_epochs': [10]\n",
        "    }\n",
        "}\n",
        "\n",
        "param_grid_svd = {\n",
        "    'n_factors': [50],\n",
        "    'n_epochs': [20],\n",
        "    'lr_all': [0.005],\n",
        "    'reg_all': [0.02]\n",
        "}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_algorithm(algo, data, algo_name):\n",
        "    \"\"\"Evaluate a single algorithm using cross-validation\"\"\"\n",
        "    try:\n",
        "        # Perform cross validation\n",
        "        cv_results = cross_validate(algo, data, measures=['RMSE', 'MAE'],\n",
        "                                  cv=3, verbose=False)\n",
        "\n",
        "        results = {\n",
        "            'Algorithm': algo_name,\n",
        "            'Mean RMSE': np.mean(cv_results['test_rmse']),\n",
        "            'Mean MAE': np.mean(cv_results['test_mae']),\n",
        "            'Std RMSE': np.std(cv_results['test_rmse']),\n",
        "            'Std MAE': np.std(cv_results['test_mae'])\n",
        "        }\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {algo_name}: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "PRUMjp0rl4h_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algorithms = [\n",
        "    (KNNBaseline(k=3, min_k=1, sim_options={'name': 'cosine', 'user_based': False}), 'KNNBaseline'),\n",
        "    (BaselineOnly(bsl_options={'method': 'als', 'n_epochs': 5}), 'BaselineOnly (ALS)'),\n",
        "    (BaselineOnly(bsl_options={'method': 'sgd', 'learning_rate': 0.005, 'n_epochs': 10}), 'BaselineOnly (SGD)'),\n",
        "    (SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02), 'SVD')\n",
        "]"
      ],
      "metadata": {
        "id": "DOF7sGkFl5QO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for algo, name in algorithms:\n",
        "    result = evaluate_algorithm(algo, data, name)\n",
        "    if result is not None:\n",
        "        results.append(result)\n",
        "if results:\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\nAlgorithm Comparison Results:\")\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Find best performing algorithm\n",
        "    best_algo = results_df.loc[results_df['Mean RMSE'].idxmin()]\n",
        "    print(f\"\\nBest performing algorithm: {best_algo['Algorithm']}\")\n",
        "    print(f\"Best RMSE: {best_algo['Mean RMSE']:.4f} (±{best_algo['Std RMSE']:.4f})\")\n",
        "    print(f\"Best MAE: {best_algo['Mean MAE']:.4f} (±{best_algo['Std MAE']:.4f})\")\n",
        "\n",
        "    # Calculate relative differences\n",
        "    baseline_rmse = results_df['Mean RMSE'].min()\n",
        "    relative_diff = (results_df['Mean RMSE'] - baseline_rmse) / baseline_rmse * 100\n",
        "\n",
        "    print(f\"\\nRelative Performance Differences (compared to {best_algo}):\")\n",
        "    for idx, row in results_df.iterrows():\n",
        "        diff = relative_diff[idx]\n",
        "        print(f\"{row['Algorithm']}: {diff:.2f}% worse than {best_algo}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHQU5Ey69PcA",
        "outputId": "dd9893f5-84ea-4be8-9044-60a3620d72d9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Error evaluating KNNBaseline: float division\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using sgd...\n",
            "Estimating biases using sgd...\n",
            "Estimating biases using sgd...\n",
            "\n",
            "Algorithm Comparison Results:\n",
            "         Algorithm  Mean RMSE  Mean MAE  Std RMSE  Std MAE\n",
            "BaselineOnly (ALS)   3.816843  3.539570  0.056160 0.027986\n",
            "BaselineOnly (SGD)   3.840093  3.559164  0.077348 0.035561\n",
            "               SVD   3.812149  3.521659  0.105167 0.051359\n",
            "\n",
            "Best performing algorithm: SVD\n",
            "Best RMSE: 3.8121 (±0.1052)\n",
            "Best MAE: 3.5217 (±0.0514)\n",
            "\n",
            "Relative Performance Differences (compared to Algorithm         SVD\n",
            "Mean RMSE    3.812149\n",
            "Mean MAE     3.521659\n",
            "Std RMSE     0.105167\n",
            "Std MAE      0.051359\n",
            "Name: 2, dtype: object):\n",
            "BaselineOnly (ALS): 0.12% worse than Algorithm         SVD\n",
            "Mean RMSE    3.812149\n",
            "Mean MAE     3.521659\n",
            "Std RMSE     0.105167\n",
            "Std MAE      0.051359\n",
            "Name: 2, dtype: object\n",
            "BaselineOnly (SGD): 0.73% worse than Algorithm         SVD\n",
            "Mean RMSE    3.812149\n",
            "Mean MAE     3.521659\n",
            "Std RMSE     0.105167\n",
            "Std MAE      0.051359\n",
            "Name: 2, dtype: object\n",
            "SVD: 0.00% worse than Algorithm         SVD\n",
            "Mean RMSE    3.812149\n",
            "Mean MAE     3.521659\n",
            "Std RMSE     0.105167\n",
            "Std MAE      0.051359\n",
            "Name: 2, dtype: object\n"
          ]
        }
      ]
    }
  ]
}